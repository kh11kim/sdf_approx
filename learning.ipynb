{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import lax, random\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optax\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "from flax.linen import initializers\n",
    "from typing import Callable, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LipLinear(nn.Module):\n",
    "    features: int\n",
    "    use_bias: bool = True\n",
    "    kernel_init: Callable = initializers.lecun_normal()\n",
    "    bias_init: Callable = initializers.zeros_init()\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        kernel = self.param('kernel',\n",
    "            self.kernel_init,\n",
    "            (jnp.shape(inputs)[-1], self.features))\n",
    "        if self.use_bias:\n",
    "            bias = self.param('bias', self.bias_init, (self.features,))\n",
    "        else:   bias = None\n",
    "        c = self.param('c', self.bias_init, 1)\n",
    "        absrowsum = jnp.sum(jnp.abs(kernel), axis=0)\n",
    "        scale = jnp.minimum(1.0, nn.softplus(c)/absrowsum)\n",
    "        y = lax.dot_general(inputs, kernel*scale,\n",
    "                        (((inputs.ndim - 1,), (0,)), ((), ())))\n",
    "        if bias is not None:\n",
    "            y += jnp.reshape(bias, (1,) * (y.ndim - 1) + (-1,))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LipMLP(nn.Module):\n",
    "    nin: int\n",
    "    features: Sequence[int]\n",
    "    skip_layer: int    \n",
    "\n",
    "    def setup(self):\n",
    "        layers = []\n",
    "        for i, dim in enumerate(self.features):\n",
    "            if i == self.skip_layer:\n",
    "                dim += self.nin\n",
    "            layers += [LipLinear(dim)]\n",
    "        self.layers = layers\n",
    "            #= [LipLinear(feat) for feat in self.features]\n",
    "\n",
    "    @staticmethod\n",
    "    def lipschitz_loss(params):\n",
    "        loss = 1.\n",
    "        for layer in params['params'].keys():\n",
    "            loss *= nn.softplus(params['params'][layer]['c'])\n",
    "        return loss[0]\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i == self.skip_layer:\n",
    "                x = jnp.hstack([x, inputs])\n",
    "            x = layer(x)\n",
    "            if i != len(self.layers) - 1:\n",
    "                x = nn.leaky_relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LipMLP(2, [10, 10, 10, 10, 1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2 = random.split(random.PRNGKey(0))\n",
    "x = random.normal(key1, (3,)) # Dummy input data\n",
    "params = model.init(key2, x) # Initialization call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss(params, x0, y0, x1, y1):\n",
    "    # Define the squared loss for a single pair (x,y)\n",
    "    def squared_error(x, y):\n",
    "        pred = model.apply(params, x)\n",
    "        return jnp.inner(y-pred, y-pred) / 2.0\n",
    "    # Vectorize the previous to compute the average of the loss on all samples.\n",
    "    x0_ = jnp.hstack([x0, jnp.zeros((x0.shape[0], 1))])\n",
    "    x1_ = jnp.hstack([x1, jnp.ones((x0.shape[0], 1))])\n",
    "    mse_loss0 = jnp.mean(jax.vmap(squared_error)(x0_, y0), axis=0)\n",
    "    mse_loss1 = jnp.mean(jax.vmap(squared_error)(x1_, y1), axis=0)\n",
    "    lip_loss = model.lipschitz_loss(params)\n",
    "    return mse_loss0 + mse_loss1 + 1e-6 * lip_loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "df_circle = pd.read_csv(\"circle.csv\")\n",
    "x_circle = jnp.array(df_circle[[\"x\", \"y\"]].to_numpy())\n",
    "y_circle = jnp.array(df_circle[[\"d\"]].to_numpy())\n",
    "df_square = pd.read_csv(\"square.csv\")\n",
    "x_square = jnp.array(df_square[[\"x\", \"y\"]].to_numpy())\n",
    "y_square = jnp.array(df_square[[\"d\"]].to_numpy())\n",
    "\n",
    "# training\n",
    "tx = optax.adam(learning_rate=0.001)\n",
    "opt_state = tx.init(params)\n",
    "loss_grad_fn = jax.value_and_grad(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss step 0:  0.25711232\n",
      "Loss step 10:  0.24767502\n",
      "Loss step 20:  0.23896672\n",
      "Loss step 30:  0.23038755\n",
      "Loss step 40:  0.2218808\n",
      "Loss step 50:  0.21343778\n",
      "Loss step 60:  0.20513578\n",
      "Loss step 70:  0.19705634\n",
      "Loss step 80:  0.18930419\n",
      "Loss step 90:  0.18195146\n",
      "Loss step 100:  0.17513928\n",
      "Loss step 110:  0.16906856\n",
      "Loss step 120:  0.16378073\n",
      "Loss step 130:  0.15940942\n",
      "Loss step 140:  0.1558566\n",
      "Loss step 150:  0.15314779\n",
      "Loss step 160:  0.15094748\n",
      "Loss step 170:  0.14886428\n",
      "Loss step 180:  0.14679715\n",
      "Loss step 190:  0.14453582\n",
      "Loss step 200:  0.14224687\n",
      "Loss step 210:  0.13990511\n",
      "Loss step 220:  0.137624\n",
      "Loss step 230:  0.13526699\n",
      "Loss step 240:  0.13287953\n",
      "Loss step 250:  0.13043515\n",
      "Loss step 260:  0.12799881\n",
      "Loss step 270:  0.12549908\n",
      "Loss step 280:  0.12297413\n",
      "Loss step 290:  0.12043692\n",
      "Loss step 300:  0.11781338\n",
      "Loss step 310:  0.115135856\n",
      "Loss step 320:  0.11232295\n",
      "Loss step 330:  0.10960936\n",
      "Loss step 340:  0.106775485\n",
      "Loss step 350:  0.10384978\n",
      "Loss step 360:  0.1007838\n",
      "Loss step 370:  0.09758453\n",
      "Loss step 380:  0.094329566\n",
      "Loss step 390:  0.091027796\n",
      "Loss step 400:  0.08764002\n",
      "Loss step 410:  0.084214985\n",
      "Loss step 420:  0.08072251\n",
      "Loss step 430:  0.07715611\n",
      "Loss step 440:  0.07365272\n",
      "Loss step 450:  0.07021179\n",
      "Loss step 460:  0.066980205\n",
      "Loss step 470:  0.06419046\n",
      "Loss step 480:  0.06170447\n",
      "Loss step 490:  0.059422757\n",
      "Loss step 500:  0.057184737\n",
      "Loss step 510:  0.05505764\n",
      "Loss step 520:  0.05298514\n",
      "Loss step 530:  0.05104338\n",
      "Loss step 540:  0.049136806\n",
      "Loss step 550:  0.04730852\n",
      "Loss step 560:  0.04555729\n",
      "Loss step 570:  0.043849964\n",
      "Loss step 580:  0.042247005\n",
      "Loss step 590:  0.040694423\n",
      "Loss step 600:  0.03919409\n",
      "Loss step 610:  0.037761774\n",
      "Loss step 620:  0.03639308\n",
      "Loss step 630:  0.035112806\n",
      "Loss step 640:  0.03387036\n",
      "Loss step 650:  0.03270111\n",
      "Loss step 660:  0.03159077\n",
      "Loss step 670:  0.030536424\n",
      "Loss step 680:  0.029539123\n",
      "Loss step 690:  0.028595675\n",
      "Loss step 700:  0.027714346\n",
      "Loss step 710:  0.026866894\n",
      "Loss step 720:  0.026072804\n",
      "Loss step 730:  0.025328044\n",
      "Loss step 740:  0.024620585\n",
      "Loss step 750:  0.023946002\n",
      "Loss step 760:  0.023312997\n",
      "Loss step 770:  0.022715144\n",
      "Loss step 780:  0.02215154\n",
      "Loss step 790:  0.021618882\n",
      "Loss step 800:  0.021102725\n",
      "Loss step 810:  0.020608133\n",
      "Loss step 820:  0.020133652\n",
      "Loss step 830:  0.01968923\n",
      "Loss step 840:  0.019270657\n",
      "Loss step 850:  0.018869339\n",
      "Loss step 860:  0.018488398\n",
      "Loss step 870:  0.018119397\n",
      "Loss step 880:  0.01776248\n",
      "Loss step 890:  0.017416673\n",
      "Loss step 900:  0.0170788\n",
      "Loss step 910:  0.016748784\n",
      "Loss step 920:  0.016426997\n",
      "Loss step 930:  0.016112866\n",
      "Loss step 940:  0.015804216\n",
      "Loss step 950:  0.015510594\n",
      "Loss step 960:  0.015228085\n",
      "Loss step 970:  0.014956831\n",
      "Loss step 980:  0.014693626\n",
      "Loss step 990:  0.01443764\n",
      "Loss step 1000:  0.014191924\n",
      "Loss step 1010:  0.013952009\n",
      "Loss step 1020:  0.0137176495\n",
      "Loss step 1030:  0.013486901\n",
      "Loss step 1040:  0.013261836\n",
      "Loss step 1050:  0.0130394325\n",
      "Loss step 1060:  0.012820011\n",
      "Loss step 1070:  0.012601116\n",
      "Loss step 1080:  0.012385114\n",
      "Loss step 1090:  0.012169988\n",
      "Loss step 1100:  0.011954794\n",
      "Loss step 1110:  0.01174199\n",
      "Loss step 1120:  0.011528801\n",
      "Loss step 1130:  0.01131808\n",
      "Loss step 1140:  0.011107491\n",
      "Loss step 1150:  0.010900184\n",
      "Loss step 1160:  0.010693829\n",
      "Loss step 1170:  0.010487304\n",
      "Loss step 1180:  0.010282322\n",
      "Loss step 1190:  0.010080401\n",
      "Loss step 1200:  0.009882656\n",
      "Loss step 1210:  0.009686444\n",
      "Loss step 1220:  0.009492311\n",
      "Loss step 1230:  0.009300414\n",
      "Loss step 1240:  0.009113154\n",
      "Loss step 1250:  0.008926266\n",
      "Loss step 1260:  0.008742638\n",
      "Loss step 1270:  0.008561833\n",
      "Loss step 1280:  0.00838302\n",
      "Loss step 1290:  0.008207222\n",
      "Loss step 1300:  0.0080337105\n",
      "Loss step 1310:  0.007863189\n",
      "Loss step 1320:  0.00769513\n",
      "Loss step 1330:  0.0075297654\n",
      "Loss step 1340:  0.0073691923\n",
      "Loss step 1350:  0.0072123907\n",
      "Loss step 1360:  0.0070593394\n",
      "Loss step 1370:  0.006909743\n",
      "Loss step 1380:  0.006765978\n",
      "Loss step 1390:  0.006626673\n",
      "Loss step 1400:  0.0064919046\n",
      "Loss step 1410:  0.0063618277\n",
      "Loss step 1420:  0.0062362603\n",
      "Loss step 1430:  0.0061143897\n",
      "Loss step 1440:  0.0059969374\n",
      "Loss step 1450:  0.005884223\n",
      "Loss step 1460:  0.005776024\n",
      "Loss step 1470:  0.005671141\n",
      "Loss step 1480:  0.0055703716\n",
      "Loss step 1490:  0.0054722675\n",
      "Loss step 1500:  0.0053782766\n",
      "Loss step 1510:  0.0052868356\n",
      "Loss step 1520:  0.005198592\n",
      "Loss step 1530:  0.005112227\n",
      "Loss step 1540:  0.0050277906\n",
      "Loss step 1550:  0.0049448884\n",
      "Loss step 1560:  0.0048640976\n",
      "Loss step 1570:  0.00478482\n",
      "Loss step 1580:  0.004706913\n",
      "Loss step 1590:  0.00463049\n",
      "Loss step 1600:  0.004555015\n",
      "Loss step 1610:  0.0044809366\n",
      "Loss step 1620:  0.004407935\n",
      "Loss step 1630:  0.004335967\n",
      "Loss step 1640:  0.0042648166\n",
      "Loss step 1650:  0.0041943183\n",
      "Loss step 1660:  0.0041255914\n",
      "Loss step 1670:  0.0040570004\n",
      "Loss step 1680:  0.0039892774\n",
      "Loss step 1690:  0.0039221365\n",
      "Loss step 1700:  0.0038552557\n",
      "Loss step 1710:  0.0037893953\n",
      "Loss step 1720:  0.0037238742\n",
      "Loss step 1730:  0.0036598705\n",
      "Loss step 1740:  0.0035973717\n",
      "Loss step 1750:  0.0035356893\n",
      "Loss step 1760:  0.0034752511\n",
      "Loss step 1770:  0.0034154924\n",
      "Loss step 1780:  0.0033562938\n",
      "Loss step 1790:  0.003297588\n",
      "Loss step 1800:  0.0032395574\n",
      "Loss step 1810:  0.0031815283\n",
      "Loss step 1820:  0.0031238226\n",
      "Loss step 1830:  0.0030659912\n",
      "Loss step 1840:  0.0030082876\n",
      "Loss step 1850:  0.0029504572\n",
      "Loss step 1860:  0.0028936313\n",
      "Loss step 1870:  0.002836325\n",
      "Loss step 1880:  0.0027799483\n",
      "Loss step 1890:  0.0027232964\n",
      "Loss step 1900:  0.0026669472\n",
      "Loss step 1910:  0.0026116916\n",
      "Loss step 1920:  0.0025568577\n",
      "Loss step 1930:  0.0025024014\n",
      "Loss step 1940:  0.002448715\n",
      "Loss step 1950:  0.0023960602\n",
      "Loss step 1960:  0.0023446032\n",
      "Loss step 1970:  0.0022949444\n",
      "Loss step 1980:  0.0022467661\n",
      "Loss step 1990:  0.002200288\n",
      "Loss step 2000:  0.0021550448\n",
      "Loss step 2010:  0.002111494\n",
      "Loss step 2020:  0.002068926\n",
      "Loss step 2030:  0.0020274124\n",
      "Loss step 2040:  0.0019868193\n",
      "Loss step 2050:  0.0019471847\n",
      "Loss step 2060:  0.0019081119\n",
      "Loss step 2070:  0.0018704835\n",
      "Loss step 2080:  0.0018338386\n",
      "Loss step 2090:  0.0017976285\n",
      "Loss step 2100:  0.001762509\n",
      "Loss step 2110:  0.0017278799\n",
      "Loss step 2120:  0.0016935421\n",
      "Loss step 2130:  0.0016594747\n",
      "Loss step 2140:  0.0016267293\n",
      "Loss step 2150:  0.0015944493\n",
      "Loss step 2160:  0.0015628481\n",
      "Loss step 2170:  0.0015315246\n",
      "Loss step 2180:  0.0015009887\n",
      "Loss step 2190:  0.0014708515\n",
      "Loss step 2200:  0.0014408564\n",
      "Loss step 2210:  0.0014111728\n",
      "Loss step 2220:  0.0013826058\n",
      "Loss step 2230:  0.0013540877\n",
      "Loss step 2240:  0.0013260331\n",
      "Loss step 2250:  0.001298308\n",
      "Loss step 2260:  0.0012713564\n",
      "Loss step 2270:  0.0012444649\n",
      "Loss step 2280:  0.0012183654\n",
      "Loss step 2290:  0.0011924614\n",
      "Loss step 2300:  0.0011669417\n",
      "Loss step 2310:  0.0011418681\n",
      "Loss step 2320:  0.0011174665\n",
      "Loss step 2330:  0.0010934356\n",
      "Loss step 2340:  0.0010699041\n",
      "Loss step 2350:  0.0010470768\n",
      "Loss step 2360:  0.0010246874\n",
      "Loss step 2370:  0.001002674\n",
      "Loss step 2380:  0.0009810823\n",
      "Loss step 2390:  0.00095986703\n",
      "Loss step 2400:  0.0009387884\n",
      "Loss step 2410:  0.00091827393\n",
      "Loss step 2420:  0.0008980387\n",
      "Loss step 2430:  0.0008785449\n",
      "Loss step 2440:  0.0008593754\n",
      "Loss step 2450:  0.0008406319\n",
      "Loss step 2460:  0.00082251284\n",
      "Loss step 2470:  0.0008046522\n",
      "Loss step 2480:  0.00078728463\n",
      "Loss step 2490:  0.0007697738\n",
      "Loss step 2500:  0.00075209135\n",
      "Loss step 2510:  0.00073584606\n",
      "Loss step 2520:  0.0007197909\n",
      "Loss step 2530:  0.00070440833\n",
      "Loss step 2540:  0.0006894233\n",
      "Loss step 2550:  0.00067504507\n",
      "Loss step 2560:  0.00066116534\n",
      "Loss step 2570:  0.00064744777\n",
      "Loss step 2580:  0.0006342634\n",
      "Loss step 2590:  0.00062172394\n",
      "Loss step 2600:  0.0006094001\n",
      "Loss step 2610:  0.00059769046\n",
      "Loss step 2620:  0.00058614573\n",
      "Loss step 2630:  0.00057488144\n",
      "Loss step 2640:  0.0005642715\n",
      "Loss step 2650:  0.0005536168\n",
      "Loss step 2660:  0.0005432831\n",
      "Loss step 2670:  0.00053318084\n",
      "Loss step 2680:  0.0005233902\n",
      "Loss step 2690:  0.00051388325\n",
      "Loss step 2700:  0.0005047655\n",
      "Loss step 2710:  0.00049600325\n",
      "Loss step 2720:  0.00048742\n",
      "Loss step 2730:  0.00047896363\n",
      "Loss step 2740:  0.00047121212\n",
      "Loss step 2750:  0.00046328089\n",
      "Loss step 2760:  0.00045562498\n",
      "Loss step 2770:  0.0004482713\n",
      "Loss step 2780:  0.00044115793\n",
      "Loss step 2790:  0.00043427802\n",
      "Loss step 2800:  0.00042816976\n",
      "Loss step 2810:  0.00042137635\n",
      "Loss step 2820:  0.0004150972\n",
      "Loss step 2830:  0.00040936345\n",
      "Loss step 2840:  0.00040329588\n",
      "Loss step 2850:  0.00039760527\n",
      "Loss step 2860:  0.00039220136\n",
      "Loss step 2870:  0.0003869237\n",
      "Loss step 2880:  0.00038173256\n",
      "Loss step 2890:  0.00037665918\n",
      "Loss step 2900:  0.0003718747\n",
      "Loss step 2910:  0.000367208\n",
      "Loss step 2920:  0.00036279383\n",
      "Loss step 2930:  0.00035980478\n",
      "Loss step 2940:  0.0003554541\n",
      "Loss step 2950:  0.00035070739\n",
      "Loss step 2960:  0.00034624228\n",
      "Loss step 2970:  0.00034225243\n",
      "Loss step 2980:  0.0003385301\n",
      "Loss step 2990:  0.00033483488\n",
      "Loss step 3000:  0.00033104862\n",
      "Loss step 3010:  0.00032752074\n",
      "Loss step 3020:  0.0003240071\n",
      "Loss step 3030:  0.0003214669\n",
      "Loss step 3040:  0.00031754308\n",
      "Loss step 3050:  0.00031485085\n",
      "Loss step 3060:  0.0003109881\n",
      "Loss step 3070:  0.00030840104\n",
      "Loss step 3080:  0.000305722\n",
      "Loss step 3090:  0.00030238114\n",
      "Loss step 3100:  0.00029977472\n",
      "Loss step 3110:  0.0002962993\n",
      "Loss step 3120:  0.0002934681\n",
      "Loss step 3130:  0.00029086252\n",
      "Loss step 3140:  0.00028810286\n",
      "Loss step 3150:  0.00028552013\n",
      "Loss step 3160:  0.0002829609\n",
      "Loss step 3170:  0.00028051448\n",
      "Loss step 3180:  0.0002780587\n",
      "Loss step 3190:  0.00027581496\n",
      "Loss step 3200:  0.00027341399\n",
      "Loss step 3210:  0.00027106554\n",
      "Loss step 3220:  0.00026910892\n",
      "Loss step 3230:  0.0002668308\n",
      "Loss step 3240:  0.00026449797\n",
      "Loss step 3250:  0.00026223515\n",
      "Loss step 3260:  0.0002604473\n",
      "Loss step 3270:  0.00025948542\n",
      "Loss step 3280:  0.000256151\n",
      "Loss step 3290:  0.00025440432\n",
      "Loss step 3300:  0.0002520464\n",
      "Loss step 3310:  0.000249865\n",
      "Loss step 3320:  0.0002485282\n",
      "Loss step 3330:  0.00024611436\n",
      "Loss step 3340:  0.00024459968\n",
      "Loss step 3350:  0.00024263993\n",
      "Loss step 3360:  0.00024052091\n",
      "Loss step 3370:  0.00023896681\n",
      "Loss step 3380:  0.00023722256\n",
      "Loss step 3390:  0.00023574446\n",
      "Loss step 3400:  0.0002335968\n",
      "Loss step 3410:  0.00023180764\n",
      "Loss step 3420:  0.00023009145\n",
      "Loss step 3430:  0.00022844267\n",
      "Loss step 3440:  0.00022737897\n",
      "Loss step 3450:  0.0002254495\n",
      "Loss step 3460:  0.00022367848\n",
      "Loss step 3470:  0.00022250139\n",
      "Loss step 3480:  0.00022125774\n",
      "Loss step 3490:  0.00021925621\n",
      "Loss step 3500:  0.00021841544\n",
      "Loss step 3510:  0.00021598821\n",
      "Loss step 3520:  0.00021468023\n",
      "Loss step 3530:  0.00021325846\n",
      "Loss step 3540:  0.00021152741\n",
      "Loss step 3550:  0.00021018655\n",
      "Loss step 3560:  0.00020873857\n",
      "Loss step 3570:  0.00020732789\n",
      "Loss step 3580:  0.000206159\n",
      "Loss step 3590:  0.00020465394\n",
      "Loss step 3600:  0.00020331892\n",
      "Loss step 3610:  0.00020201968\n",
      "Loss step 3620:  0.00020079805\n",
      "Loss step 3630:  0.00019988252\n",
      "Loss step 3640:  0.0001983703\n",
      "Loss step 3650:  0.00019772015\n",
      "Loss step 3660:  0.00019599241\n",
      "Loss step 3670:  0.00019467126\n",
      "Loss step 3680:  0.00019412192\n",
      "Loss step 3690:  0.00019352943\n",
      "Loss step 3700:  0.00019168275\n",
      "Loss step 3710:  0.00019031022\n",
      "Loss step 3720:  0.00018893673\n",
      "Loss step 3730:  0.00018780594\n",
      "Loss step 3740:  0.00018733669\n",
      "Loss step 3750:  0.00018567657\n",
      "Loss step 3760:  0.00018444798\n",
      "Loss step 3770:  0.00018338801\n",
      "Loss step 3780:  0.00018220089\n",
      "Loss step 3790:  0.00018116407\n",
      "Loss step 3800:  0.00018022725\n",
      "Loss step 3810:  0.00017931423\n",
      "Loss step 3820:  0.0001780897\n",
      "Loss step 3830:  0.00017737548\n",
      "Loss step 3840:  0.0001765449\n",
      "Loss step 3850:  0.00017555301\n",
      "Loss step 3860:  0.00017462441\n",
      "Loss step 3870:  0.00017410942\n",
      "Loss step 3880:  0.00017329285\n",
      "Loss step 3890:  0.00017150423\n",
      "Loss step 3900:  0.00017077582\n",
      "Loss step 3910:  0.00017139515\n",
      "Loss step 3920:  0.00016887805\n",
      "Loss step 3930:  0.00016781979\n",
      "Loss step 3940:  0.0001710458\n",
      "Loss step 3950:  0.00016692429\n",
      "Loss step 3960:  0.00016550421\n",
      "Loss step 3970:  0.00016442567\n",
      "Loss step 3980:  0.00016342005\n",
      "Loss step 3990:  0.00016247101\n",
      "Loss step 4000:  0.00016156024\n",
      "Loss step 4010:  0.00016068685\n",
      "Loss step 4020:  0.00015982812\n",
      "Loss step 4030:  0.00015899564\n",
      "Loss step 4040:  0.000158157\n",
      "Loss step 4050:  0.00015733088\n",
      "Loss step 4060:  0.00015653133\n",
      "Loss step 4070:  0.00015569302\n",
      "Loss step 4080:  0.00015486073\n",
      "Loss step 4090:  0.00015405662\n",
      "Loss step 4100:  0.00015329669\n",
      "Loss step 4110:  0.00015249709\n",
      "Loss step 4120:  0.00015171774\n",
      "Loss step 4130:  0.00015099489\n",
      "Loss step 4140:  0.00015042351\n",
      "Loss step 4150:  0.0001495439\n",
      "Loss step 4160:  0.00014879895\n",
      "Loss step 4170:  0.00014798013\n",
      "Loss step 4180:  0.00014721829\n",
      "Loss step 4190:  0.00014727136\n",
      "Loss step 4200:  0.00014849725\n",
      "Loss step 4210:  0.00014638154\n",
      "Loss step 4220:  0.00014517651\n",
      "Loss step 4230:  0.00014424454\n",
      "Loss step 4240:  0.0001432208\n",
      "Loss step 4250:  0.00014250433\n",
      "Loss step 4260:  0.00014208784\n",
      "Loss step 4270:  0.0001413876\n",
      "Loss step 4280:  0.00014065459\n",
      "Loss step 4290:  0.00014244477\n",
      "Loss step 4300:  0.00013995069\n",
      "Loss step 4310:  0.00013918911\n",
      "Loss step 4320:  0.0001382546\n",
      "Loss step 4330:  0.00013754475\n",
      "Loss step 4340:  0.00013734434\n",
      "Loss step 4350:  0.00013646591\n",
      "Loss step 4360:  0.0001357716\n",
      "Loss step 4370:  0.00013520526\n",
      "Loss step 4380:  0.00013470754\n",
      "Loss step 4390:  0.00013394162\n",
      "Loss step 4400:  0.00013336288\n",
      "Loss step 4410:  0.0001328047\n",
      "Loss step 4420:  0.00013215742\n",
      "Loss step 4430:  0.00014425092\n",
      "Loss step 4440:  0.00013702\n",
      "Loss step 4450:  0.00013190701\n",
      "Loss step 4460:  0.00013080922\n",
      "Loss step 4470:  0.00012988946\n",
      "Loss step 4480:  0.00012917804\n",
      "Loss step 4490:  0.00012847652\n",
      "Loss step 4500:  0.00012782316\n",
      "Loss step 4510:  0.00012723022\n",
      "Loss step 4520:  0.00012669055\n",
      "Loss step 4530:  0.00012613677\n",
      "Loss step 4540:  0.0001256072\n",
      "Loss step 4550:  0.00012507335\n",
      "Loss step 4560:  0.00012459149\n",
      "Loss step 4570:  0.00012409576\n",
      "Loss step 4580:  0.00012361513\n",
      "Loss step 4590:  0.0001231314\n",
      "Loss step 4600:  0.00012323698\n",
      "Loss step 4610:  0.0001226143\n",
      "Loss step 4620:  0.000121929836\n",
      "Loss step 4630:  0.00012131236\n",
      "Loss step 4640:  0.000120847515\n",
      "Loss step 4650:  0.00012041143\n",
      "Loss step 4660:  0.00012003526\n",
      "Loss step 4670:  0.00012020843\n",
      "Loss step 4680:  0.00011964252\n",
      "Loss step 4690:  0.000119040655\n",
      "Loss step 4700:  0.00011958088\n",
      "Loss step 4710:  0.00012264735\n",
      "Loss step 4720:  0.00011906379\n",
      "Loss step 4730:  0.00011740744\n",
      "Loss step 4740:  0.00011666032\n",
      "Loss step 4750:  0.00011612324\n",
      "Loss step 4760:  0.000116813346\n",
      "Loss step 4770:  0.0001154288\n",
      "Loss step 4780:  0.0001151745\n",
      "Loss step 4790:  0.000116786134\n",
      "Loss step 4800:  0.000116199466\n",
      "Loss step 4810:  0.000115170806\n",
      "Loss step 4820:  0.00011400661\n",
      "Loss step 4830:  0.00011323441\n",
      "Loss step 4840:  0.0001127135\n",
      "Loss step 4850:  0.00011226158\n",
      "Loss step 4860:  0.00011186268\n",
      "Loss step 4870:  0.000111563335\n",
      "Loss step 4880:  0.00011141685\n",
      "Loss step 4890:  0.0001109011\n",
      "Loss step 4900:  0.000110555215\n",
      "Loss step 4910:  0.000110292\n",
      "Loss step 4920:  0.00011010879\n",
      "Loss step 4930:  0.00010983208\n",
      "Loss step 4940:  0.00010924367\n",
      "Loss step 4950:  0.000108794\n",
      "Loss step 4960:  0.00011000681\n",
      "Loss step 4970:  0.000108808315\n",
      "Loss step 4980:  0.00010810297\n",
      "Loss step 4990:  0.00010906651\n",
      "Loss step 5000:  0.000107996966\n",
      "Loss step 5010:  0.00010707025\n",
      "Loss step 5020:  0.00010883084\n",
      "Loss step 5030:  0.00010718125\n",
      "Loss step 5040:  0.000106099025\n",
      "Loss step 5050:  0.000110951405\n",
      "Loss step 5060:  0.00010692716\n",
      "Loss step 5070:  0.00010550346\n",
      "Loss step 5080:  0.00010511013\n",
      "Loss step 5090:  0.00010574989\n",
      "Loss step 5100:  0.000106091116\n",
      "Loss step 5110:  0.00010439398\n",
      "Loss step 5120:  0.00010376859\n",
      "Loss step 5130:  0.00010339459\n",
      "Loss step 5140:  0.00010359553\n",
      "Loss step 5150:  0.0001031548\n",
      "Loss step 5160:  0.000102778904\n",
      "Loss step 5170:  0.00010249534\n",
      "Loss step 5180:  0.00010204753\n",
      "Loss step 5190:  0.00010165071\n",
      "Loss step 5200:  0.000105222935\n",
      "Loss step 5210:  0.000101186975\n",
      "Loss step 5220:  0.00010134183\n",
      "Loss step 5230:  0.000100612175\n",
      "Loss step 5240:  0.000100273\n",
      "Loss step 5250:  0.00010028904\n",
      "Loss step 5260:  0.000106335225\n",
      "Loss step 5270:  0.00010316124\n",
      "Loss step 5280:  0.00010074893\n",
      "Loss step 5290:  9.9619756e-05\n",
      "Loss step 5300:  9.899786e-05\n",
      "Loss step 5310:  9.861802e-05\n",
      "Loss step 5320:  9.826378e-05\n",
      "Loss step 5330:  9.808114e-05\n",
      "Loss step 5340:  9.770285e-05\n",
      "Loss step 5350:  9.813876e-05\n",
      "Loss step 5360:  9.730746e-05\n",
      "Loss step 5370:  9.709662e-05\n",
      "Loss step 5380:  9.683296e-05\n",
      "Loss step 5390:  9.681812e-05\n",
      "Loss step 5400:  9.6338495e-05\n",
      "Loss step 5410:  9.614861e-05\n",
      "Loss step 5420:  9.5814554e-05\n",
      "Loss step 5430:  9.556739e-05\n",
      "Loss step 5440:  0.000100907\n",
      "Loss step 5450:  0.00010001861\n",
      "Loss step 5460:  9.730528e-05\n",
      "Loss step 5470:  9.573608e-05\n",
      "Loss step 5480:  9.514822e-05\n",
      "Loss step 5490:  9.462906e-05\n",
      "Loss step 5500:  9.4272364e-05\n",
      "Loss step 5510:  9.394127e-05\n",
      "Loss step 5520:  9.3705334e-05\n",
      "Loss step 5530:  9.3528666e-05\n",
      "Loss step 5540:  9.3316085e-05\n",
      "Loss step 5550:  9.315872e-05\n",
      "Loss step 5560:  9.283935e-05\n",
      "Loss step 5570:  9.2745184e-05\n",
      "Loss step 5580:  9.255033e-05\n",
      "Loss step 5590:  9.233432e-05\n",
      "Loss step 5600:  9.268889e-05\n",
      "Loss step 5610:  9.1890455e-05\n",
      "Loss step 5620:  9.166668e-05\n",
      "Loss step 5630:  9.166633e-05\n",
      "Loss step 5640:  9.158086e-05\n",
      "Loss step 5650:  9.1153146e-05\n",
      "Loss step 5660:  9.084774e-05\n",
      "Loss step 5670:  0.000106377236\n",
      "Loss step 5680:  9.398584e-05\n",
      "Loss step 5690:  9.158175e-05\n",
      "Loss step 5700:  9.068265e-05\n",
      "Loss step 5710:  9.0260444e-05\n",
      "Loss step 5720:  9.0046706e-05\n",
      "Loss step 5730:  8.9654575e-05\n",
      "Loss step 5740:  8.955022e-05\n",
      "Loss step 5750:  8.9976566e-05\n",
      "Loss step 5760:  8.947237e-05\n",
      "Loss step 5770:  8.953841e-05\n",
      "Loss step 5780:  9.047391e-05\n",
      "Loss step 5790:  8.859426e-05\n",
      "Loss step 5800:  8.8387955e-05\n",
      "Loss step 5810:  9.87902e-05\n",
      "Loss step 5820:  9.3518545e-05\n",
      "Loss step 5830:  9.650523e-05\n",
      "Loss step 5840:  9.018478e-05\n",
      "Loss step 5850:  8.848221e-05\n",
      "Loss step 5860:  8.794544e-05\n",
      "Loss step 5870:  8.76675e-05\n",
      "Loss step 5880:  8.733491e-05\n",
      "Loss step 5890:  8.7065644e-05\n",
      "Loss step 5900:  8.684061e-05\n",
      "Loss step 5910:  8.663038e-05\n",
      "Loss step 5920:  8.642961e-05\n",
      "Loss step 5930:  8.623633e-05\n",
      "Loss step 5940:  8.605205e-05\n",
      "Loss step 5950:  8.5879394e-05\n",
      "Loss step 5960:  8.57097e-05\n",
      "Loss step 5970:  8.5548956e-05\n",
      "Loss step 5980:  8.539857e-05\n",
      "Loss step 5990:  8.521854e-05\n",
      "Loss step 6000:  8.510322e-05\n",
      "Loss step 6010:  8.490098e-05\n",
      "Loss step 6020:  8.472523e-05\n",
      "Loss step 6030:  8.459048e-05\n",
      "Loss step 6040:  8.4528336e-05\n",
      "Loss step 6050:  8.42819e-05\n",
      "Loss step 6060:  8.409831e-05\n",
      "Loss step 6070:  8.747423e-05\n",
      "Loss step 6080:  8.482404e-05\n",
      "Loss step 6090:  8.397887e-05\n",
      "Loss step 6100:  8.395263e-05\n",
      "Loss step 6110:  0.00010656254\n",
      "Loss step 6120:  8.371654e-05\n",
      "Loss step 6130:  8.339803e-05\n",
      "Loss step 6140:  8.321097e-05\n",
      "Loss step 6150:  8.3048675e-05\n",
      "Loss step 6160:  8.2781014e-05\n",
      "Loss step 6170:  8.255425e-05\n",
      "Loss step 6180:  8.236168e-05\n",
      "Loss step 6190:  8.2190345e-05\n",
      "Loss step 6200:  8.20165e-05\n",
      "Loss step 6210:  8.1859136e-05\n",
      "Loss step 6220:  8.170578e-05\n",
      "Loss step 6230:  8.156184e-05\n",
      "Loss step 6240:  8.142145e-05\n",
      "Loss step 6250:  8.129115e-05\n",
      "Loss step 6260:  8.123471e-05\n",
      "Loss step 6270:  8.1062266e-05\n",
      "Loss step 6280:  8.104204e-05\n",
      "Loss step 6290:  8.1475024e-05\n",
      "Loss step 6300:  8.0677986e-05\n",
      "Loss step 6310:  8.0502745e-05\n",
      "Loss step 6320:  8.039888e-05\n",
      "Loss step 6330:  8.029839e-05\n",
      "Loss step 6340:  8.109988e-05\n",
      "Loss step 6350:  8.170572e-05\n",
      "Loss step 6360:  8.055294e-05\n",
      "Loss step 6370:  8.055341e-05\n",
      "Loss step 6380:  7.989997e-05\n",
      "Loss step 6390:  7.9972495e-05\n",
      "Loss step 6400:  7.95356e-05\n",
      "Loss step 6410:  7.935974e-05\n",
      "Loss step 6420:  7.911217e-05\n",
      "Loss step 6430:  7.8948346e-05\n",
      "Loss step 6440:  7.877348e-05\n",
      "Loss step 6450:  7.8606674e-05\n",
      "Loss step 6460:  7.844731e-05\n",
      "Loss step 6470:  7.829206e-05\n",
      "Loss step 6480:  7.813842e-05\n",
      "Loss step 6490:  7.799489e-05\n",
      "Loss step 6500:  7.8845726e-05\n",
      "Loss step 6510:  7.81816e-05\n",
      "Loss step 6520:  7.8472505e-05\n",
      "Loss step 6530:  7.792076e-05\n",
      "Loss step 6540:  7.7470584e-05\n",
      "Loss step 6550:  8.030008e-05\n",
      "Loss step 6560:  7.757289e-05\n",
      "Loss step 6570:  7.815231e-05\n",
      "Loss step 6580:  7.705402e-05\n",
      "Loss step 6590:  7.690898e-05\n",
      "Loss step 6600:  7.709326e-05\n",
      "Loss step 6610:  8.974387e-05\n",
      "Loss step 6620:  8.211837e-05\n",
      "Loss step 6630:  7.863846e-05\n",
      "Loss step 6640:  7.770588e-05\n",
      "Loss step 6650:  7.659472e-05\n",
      "Loss step 6660:  7.637693e-05\n",
      "Loss step 6670:  7.641794e-05\n",
      "Loss step 6680:  7.596368e-05\n",
      "Loss step 6690:  7.5832395e-05\n",
      "Loss step 6700:  7.60055e-05\n",
      "Loss step 6710:  9.396631e-05\n",
      "Loss step 6720:  8.249037e-05\n",
      "Loss step 6730:  7.784408e-05\n",
      "Loss step 6740:  7.6180026e-05\n",
      "Loss step 6750:  7.5505704e-05\n",
      "Loss step 6760:  7.513623e-05\n",
      "Loss step 6770:  7.493443e-05\n",
      "Loss step 6780:  7.478919e-05\n",
      "Loss step 6790:  7.463422e-05\n",
      "Loss step 6800:  7.44925e-05\n",
      "Loss step 6810:  7.437069e-05\n",
      "Loss step 6820:  7.423325e-05\n",
      "Loss step 6830:  7.411429e-05\n",
      "Loss step 6840:  7.424113e-05\n",
      "Loss step 6850:  7.386838e-05\n",
      "Loss step 6860:  7.374167e-05\n",
      "Loss step 6870:  7.382896e-05\n",
      "Loss step 6880:  7.36521e-05\n",
      "Loss step 6890:  7.347733e-05\n",
      "Loss step 6900:  7.3352654e-05\n",
      "Loss step 6910:  7.3178126e-05\n",
      "Loss step 6920:  7.3064715e-05\n",
      "Loss step 6930:  7.657653e-05\n",
      "Loss step 6940:  7.801913e-05\n",
      "Loss step 6950:  7.306175e-05\n",
      "Loss step 6960:  7.321276e-05\n",
      "Loss step 6970:  7.323788e-05\n",
      "Loss step 6980:  7.3331394e-05\n",
      "Loss step 6990:  7.272017e-05\n",
      "Loss step 7000:  7.233853e-05\n",
      "Loss step 7010:  7.2214796e-05\n",
      "Loss step 7020:  7.7284596e-05\n",
      "Loss step 7030:  7.253316e-05\n",
      "Loss step 7040:  7.323251e-05\n",
      "Loss step 7050:  7.2052586e-05\n",
      "Loss step 7060:  7.182923e-05\n",
      "Loss step 7070:  7.170576e-05\n",
      "Loss step 7080:  7.154124e-05\n",
      "Loss step 7090:  7.1442315e-05\n",
      "Loss step 7100:  7.146054e-05\n",
      "Loss step 7110:  7.12299e-05\n",
      "Loss step 7120:  7.1129245e-05\n",
      "Loss step 7130:  7.1839495e-05\n",
      "Loss step 7140:  7.1384195e-05\n",
      "Loss step 7150:  7.115977e-05\n",
      "Loss step 7160:  7.102427e-05\n",
      "Loss step 7170:  7.0714144e-05\n",
      "Loss step 7180:  7.058107e-05\n",
      "Loss step 7190:  7.051698e-05\n",
      "Loss step 7200:  7.12187e-05\n",
      "Loss step 7210:  7.160941e-05\n",
      "Loss step 7220:  7.087696e-05\n",
      "Loss step 7230:  7.068708e-05\n",
      "Loss step 7240:  7.044592e-05\n",
      "Loss step 7250:  7.027757e-05\n",
      "Loss step 7260:  7.0124675e-05\n",
      "Loss step 7270:  6.998002e-05\n",
      "Loss step 7280:  6.985247e-05\n",
      "Loss step 7290:  6.984052e-05\n",
      "Loss step 7300:  7.184218e-05\n",
      "Loss step 7310:  7.073441e-05\n",
      "Loss step 7320:  7.004898e-05\n",
      "Loss step 7330:  6.9658476e-05\n",
      "Loss step 7340:  6.940258e-05\n",
      "Loss step 7350:  6.924573e-05\n",
      "Loss step 7360:  6.914749e-05\n",
      "Loss step 7370:  6.998911e-05\n",
      "Loss step 7380:  7.869843e-05\n",
      "Loss step 7390:  6.9437985e-05\n",
      "Loss step 7400:  7.0245995e-05\n",
      "Loss step 7410:  6.921194e-05\n",
      "Loss step 7420:  6.889385e-05\n",
      "Loss step 7430:  6.876668e-05\n",
      "Loss step 7440:  6.862856e-05\n",
      "Loss step 7450:  6.8494046e-05\n",
      "Loss step 7460:  6.838127e-05\n",
      "Loss step 7470:  6.827169e-05\n",
      "Loss step 7480:  6.841995e-05\n",
      "Loss step 7490:  6.9366404e-05\n",
      "Loss step 7500:  6.899829e-05\n",
      "Loss step 7510:  6.816287e-05\n",
      "Loss step 7520:  6.794292e-05\n",
      "Loss step 7530:  6.787411e-05\n",
      "Loss step 7540:  6.775218e-05\n",
      "Loss step 7550:  6.7656394e-05\n",
      "Loss step 7560:  6.757173e-05\n",
      "Loss step 7570:  6.845976e-05\n",
      "Loss step 7580:  6.800385e-05\n",
      "Loss step 7590:  6.7446716e-05\n",
      "Loss step 7600:  6.735863e-05\n",
      "Loss step 7610:  6.7277666e-05\n",
      "Loss step 7620:  8.667303e-05\n",
      "Loss step 7630:  7.104991e-05\n",
      "Loss step 7640:  6.809066e-05\n",
      "Loss step 7650:  6.729373e-05\n",
      "Loss step 7660:  6.696985e-05\n",
      "Loss step 7670:  6.683013e-05\n",
      "Loss step 7680:  6.672412e-05\n",
      "Loss step 7690:  6.6621025e-05\n",
      "Loss step 7700:  6.652861e-05\n",
      "Loss step 7710:  6.643882e-05\n",
      "Loss step 7720:  6.635083e-05\n",
      "Loss step 7730:  6.6272e-05\n",
      "Loss step 7740:  6.744712e-05\n",
      "Loss step 7750:  6.844213e-05\n",
      "Loss step 7760:  6.69786e-05\n",
      "Loss step 7770:  6.6141685e-05\n",
      "Loss step 7780:  6.597674e-05\n",
      "Loss step 7790:  6.5909655e-05\n",
      "Loss step 7800:  6.5801694e-05\n",
      "Loss step 7810:  6.571203e-05\n",
      "Loss step 7820:  6.562168e-05\n",
      "Loss step 7830:  6.563971e-05\n",
      "Loss step 7840:  6.631953e-05\n",
      "Loss step 7850:  6.6157154e-05\n",
      "Loss step 7860:  6.541032e-05\n",
      "Loss step 7870:  6.530873e-05\n",
      "Loss step 7880:  6.521023e-05\n",
      "Loss step 7890:  6.545131e-05\n",
      "Loss step 7900:  6.584444e-05\n",
      "Loss step 7910:  6.553518e-05\n",
      "Loss step 7920:  6.504754e-05\n",
      "Loss step 7930:  6.4895605e-05\n",
      "Loss step 7940:  7.050376e-05\n",
      "Loss step 7950:  8.438208e-05\n",
      "Loss step 7960:  6.860101e-05\n",
      "Loss step 7970:  6.640859e-05\n",
      "Loss step 7980:  6.515299e-05\n",
      "Loss step 7990:  6.5103006e-05\n",
      "Loss step 8000:  6.4821914e-05\n",
      "Loss step 8010:  6.466498e-05\n",
      "Loss step 8020:  6.452005e-05\n",
      "Loss step 8030:  6.4423395e-05\n",
      "Loss step 8040:  6.433275e-05\n",
      "Loss step 8050:  6.424507e-05\n",
      "Loss step 8060:  6.415857e-05\n",
      "Loss step 8070:  6.407836e-05\n",
      "Loss step 8080:  6.39982e-05\n",
      "Loss step 8090:  6.391829e-05\n",
      "Loss step 8100:  6.383808e-05\n",
      "Loss step 8110:  6.3757514e-05\n",
      "Loss step 8120:  6.367656e-05\n",
      "Loss step 8130:  6.3594634e-05\n",
      "Loss step 8140:  6.3513944e-05\n",
      "Loss step 8150:  6.343157e-05\n",
      "Loss step 8160:  6.335026e-05\n",
      "Loss step 8170:  6.327056e-05\n",
      "Loss step 8180:  6.320889e-05\n",
      "Loss step 8190:  6.318996e-05\n",
      "Loss step 8200:  6.333609e-05\n",
      "Loss step 8210:  6.31383e-05\n",
      "Loss step 8220:  6.29232e-05\n",
      "Loss step 8230:  6.281582e-05\n",
      "Loss step 8240:  6.332869e-05\n",
      "Loss step 8250:  6.296635e-05\n",
      "Loss step 8260:  6.280281e-05\n",
      "Loss step 8270:  6.257429e-05\n",
      "Loss step 8280:  6.243917e-05\n",
      "Loss step 8290:  6.263424e-05\n",
      "Loss step 8300:  6.4169464e-05\n",
      "Loss step 8310:  6.318773e-05\n",
      "Loss step 8320:  6.256325e-05\n",
      "Loss step 8330:  6.2168205e-05\n",
      "Loss step 8340:  6.2107945e-05\n",
      "Loss step 8350:  6.23908e-05\n",
      "Loss step 8360:  6.2486164e-05\n",
      "Loss step 8370:  7.012717e-05\n",
      "Loss step 8380:  6.4151405e-05\n",
      "Loss step 8390:  6.3151e-05\n",
      "Loss step 8400:  6.2043604e-05\n",
      "Loss step 8410:  6.163094e-05\n",
      "Loss step 8420:  6.139411e-05\n",
      "Loss step 8430:  6.154553e-05\n",
      "Loss step 8440:  6.123589e-05\n",
      "Loss step 8450:  6.111275e-05\n",
      "Loss step 8460:  6.110324e-05\n",
      "Loss step 8470:  6.11739e-05\n",
      "Loss step 8480:  6.0827406e-05\n",
      "Loss step 8490:  6.0975864e-05\n",
      "Loss step 8500:  6.12311e-05\n",
      "Loss step 8510:  6.426551e-05\n",
      "Loss step 8520:  6.156301e-05\n",
      "Loss step 8530:  6.052888e-05\n",
      "Loss step 8540:  6.0495295e-05\n",
      "Loss step 8550:  6.668018e-05\n",
      "Loss step 8560:  6.331427e-05\n",
      "Loss step 8570:  6.146588e-05\n",
      "Loss step 8580:  6.0316077e-05\n",
      "Loss step 8590:  6.0495484e-05\n",
      "Loss step 8600:  5.9998132e-05\n",
      "Loss step 8610:  5.984724e-05\n",
      "Loss step 8620:  5.9762642e-05\n",
      "Loss step 8630:  8.80485e-05\n",
      "Loss step 8640:  6.49435e-05\n",
      "Loss step 8650:  6.215444e-05\n",
      "Loss step 8660:  5.995612e-05\n",
      "Loss step 8670:  5.971903e-05\n",
      "Loss step 8680:  5.9619168e-05\n",
      "Loss step 8690:  5.947343e-05\n",
      "Loss step 8700:  5.935189e-05\n",
      "Loss step 8710:  5.924354e-05\n",
      "Loss step 8720:  5.914428e-05\n",
      "Loss step 8730:  5.9051297e-05\n",
      "Loss step 8740:  5.896274e-05\n",
      "Loss step 8750:  5.887314e-05\n",
      "Loss step 8760:  5.8787296e-05\n",
      "Loss step 8770:  5.8708873e-05\n",
      "Loss step 8780:  5.870085e-05\n",
      "Loss step 8790:  5.8578036e-05\n",
      "Loss step 8800:  5.84889e-05\n",
      "Loss step 8810:  5.9011894e-05\n",
      "Loss step 8820:  5.9154794e-05\n",
      "Loss step 8830:  5.8341728e-05\n",
      "Loss step 8840:  5.830322e-05\n",
      "Loss step 8850:  6.086005e-05\n",
      "Loss step 8860:  5.9002796e-05\n",
      "Loss step 8870:  5.8443242e-05\n",
      "Loss step 8880:  6.1112936e-05\n",
      "Loss step 8890:  5.8021822e-05\n",
      "Loss step 8900:  5.7823287e-05\n",
      "Loss step 8910:  5.7792833e-05\n",
      "Loss step 8920:  5.8289894e-05\n",
      "Loss step 8930:  5.7821133e-05\n",
      "Loss step 8940:  5.750319e-05\n",
      "Loss step 8950:  5.7491623e-05\n",
      "Loss step 8960:  5.7441357e-05\n",
      "Loss step 8970:  5.8612157e-05\n",
      "Loss step 8980:  5.8678987e-05\n",
      "Loss step 8990:  5.7605208e-05\n",
      "Loss step 9000:  5.7318288e-05\n",
      "Loss step 9010:  5.718416e-05\n",
      "Loss step 9020:  5.7022597e-05\n",
      "Loss step 9030:  5.6926423e-05\n",
      "Loss step 9040:  7.682631e-05\n",
      "Loss step 9050:  5.8977836e-05\n",
      "Loss step 9060:  5.7175534e-05\n",
      "Loss step 9070:  5.7478253e-05\n",
      "Loss step 9080:  5.7149155e-05\n",
      "Loss step 9090:  5.676203e-05\n",
      "Loss step 9100:  5.6608795e-05\n",
      "Loss step 9110:  5.6507663e-05\n",
      "Loss step 9120:  5.640776e-05\n",
      "Loss step 9130:  5.635326e-05\n",
      "Loss step 9140:  5.6240762e-05\n",
      "Loss step 9150:  5.6876153e-05\n",
      "Loss step 9160:  5.6336597e-05\n",
      "Loss step 9170:  5.622234e-05\n",
      "Loss step 9180:  5.598113e-05\n",
      "Loss step 9190:  5.644573e-05\n",
      "Loss step 9200:  5.9664395e-05\n",
      "Loss step 9210:  5.6076264e-05\n",
      "Loss step 9220:  5.623807e-05\n",
      "Loss step 9230:  5.6121273e-05\n",
      "Loss step 9240:  5.5709177e-05\n",
      "Loss step 9250:  5.5557604e-05\n",
      "Loss step 9260:  5.549998e-05\n",
      "Loss step 9270:  5.5415047e-05\n",
      "Loss step 9280:  5.579436e-05\n",
      "Loss step 9290:  5.8406837e-05\n",
      "Loss step 9300:  5.8888534e-05\n",
      "Loss step 9310:  5.559536e-05\n",
      "Loss step 9320:  5.5587672e-05\n",
      "Loss step 9330:  5.5490927e-05\n",
      "Loss step 9340:  5.5262888e-05\n",
      "Loss step 9350:  5.5097058e-05\n",
      "Loss step 9360:  5.4980195e-05\n",
      "Loss step 9370:  5.498646e-05\n",
      "Loss step 9380:  5.4815067e-05\n",
      "Loss step 9390:  5.474037e-05\n",
      "Loss step 9400:  5.466599e-05\n",
      "Loss step 9410:  5.4591834e-05\n",
      "Loss step 9420:  5.4583797e-05\n",
      "Loss step 9430:  5.4678057e-05\n",
      "Loss step 9440:  5.4603166e-05\n",
      "Loss step 9450:  5.4495315e-05\n",
      "Loss step 9460:  5.435867e-05\n",
      "Loss step 9470:  5.426336e-05\n",
      "Loss step 9480:  5.605927e-05\n",
      "Loss step 9490:  5.709891e-05\n",
      "Loss step 9500:  5.4867895e-05\n",
      "Loss step 9510:  5.453477e-05\n",
      "Loss step 9520:  5.4320186e-05\n",
      "Loss step 9530:  5.404222e-05\n",
      "Loss step 9540:  5.3971064e-05\n",
      "Loss step 9550:  5.387777e-05\n",
      "Loss step 9560:  5.378882e-05\n",
      "Loss step 9570:  5.3712447e-05\n",
      "Loss step 9580:  5.3663734e-05\n",
      "Loss step 9590:  5.5788834e-05\n",
      "Loss step 9600:  5.3747586e-05\n",
      "Loss step 9610:  5.400739e-05\n",
      "Loss step 9620:  5.4038715e-05\n",
      "Loss step 9630:  5.3510397e-05\n",
      "Loss step 9640:  5.3419877e-05\n",
      "Loss step 9650:  5.333535e-05\n",
      "Loss step 9660:  5.3245494e-05\n",
      "Loss step 9670:  5.318354e-05\n",
      "Loss step 9680:  5.3149222e-05\n",
      "Loss step 9690:  5.3266955e-05\n",
      "Loss step 9700:  5.3148888e-05\n",
      "Loss step 9710:  5.2985994e-05\n",
      "Loss step 9720:  5.3859945e-05\n",
      "Loss step 9730:  8.235919e-05\n",
      "Loss step 9740:  5.5508477e-05\n",
      "Loss step 9750:  5.358113e-05\n",
      "Loss step 9760:  5.3421103e-05\n",
      "Loss step 9770:  5.3088443e-05\n",
      "Loss step 9780:  5.2940675e-05\n",
      "Loss step 9790:  5.277037e-05\n",
      "Loss step 9800:  5.2648385e-05\n",
      "Loss step 9810:  5.256947e-05\n",
      "Loss step 9820:  5.2501942e-05\n",
      "Loss step 9830:  5.2437917e-05\n",
      "Loss step 9840:  5.237621e-05\n",
      "Loss step 9850:  5.231151e-05\n",
      "Loss step 9860:  5.2249274e-05\n",
      "Loss step 9870:  5.2186126e-05\n",
      "Loss step 9880:  5.2123123e-05\n",
      "Loss step 9890:  5.2071515e-05\n",
      "Loss step 9900:  5.2001298e-05\n",
      "Loss step 9910:  5.200378e-05\n",
      "Loss step 9920:  5.1925395e-05\n",
      "Loss step 9930:  5.1866242e-05\n",
      "Loss step 9940:  5.1785562e-05\n",
      "Loss step 9950:  5.5083045e-05\n",
      "Loss step 9960:  5.177452e-05\n",
      "Loss step 9970:  5.1915307e-05\n",
      "Loss step 9980:  5.1613344e-05\n",
      "Loss step 9990:  5.153232e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    loss_val, grads = loss_grad_fn(params, x_circle, y_circle, x_square, y_square)\n",
    "    updates, opt_state = tx.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    if i % 10 == 0:\n",
    "        print('Loss step {}: '.format(i), loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up grid size and circle parameters\n",
    "n = 50\n",
    "x = jnp.linspace(-1.5,1.5,n)\n",
    "y = jnp.linspace(-1.5,1.5,n)\n",
    "X, Y = jnp.meshgrid(x,y)\n",
    "xy = jnp.hstack([X.reshape(-1,1), Y.reshape(-1,1)])\n",
    "xy0 = jnp.hstack([xy, jnp.zeros((xy.shape[0], 1))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9QAAADFCAYAAAC1tronAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1ZUlEQVR4nO2dTaie1fnu7x1r9k7Mh9kxRIKxIo46SYsS/3VyLAREOEIpSCcHouU4kDqKE50oDiSzIvQIhR5aC/+JowrnDDoJcpxYpHoydCBIkyLGmp3mY5u9I8n+D3afnXe/+/1YH/fnWtcP9sCYvO/zvvu6nrWuda91PwsbGxsbBAAAAAAAAAAAgCx2WV8AAAAAAAAAAAAQEQRqAAAAAAAAAACgAARqAAAAAAAAAACgAARqAAAAAAAAAACgAARqAAAAAAAAAACgAARqAAAAAAAAAACgAARqAAAAAAAAAACggB9YX8As7ty5Q1999RXt37+fFhYWrC8HdMjGxgZdv36djh07Rrt26a8/wQPAEugf9Az0D3oHHgA9k6N/14H6q6++ouPHj1tfBgB08eJFeuihh9TfFx4AHoD+Qc9A/6B34AHQMyn6dx2o9+/fT0RE/+f//1+6b/99U//ev9ZuZL/2lfXrRdd05ea1on83i5V1/tfUYnnxAOvrHdpT93qHFvdn/f37l/bN/P+r11fpuZ/89y0tajPugehazyGyL4h4vVHjixpPeNH/f/71fdq7b+/cvx9V6ylE98NAJF98d+M7+h//8UuX+i/RuuT8Zd7vtRX9SuLBG+O+8OKB//X//jftSRgDBji1Du3aYumLmze+o1f+2/9M0r/rQD1s77hv/320b//O4HNlbXNAue/e6WF7Eitr12jvvenG3Pp3N6/Snn17sv/dJC6v3TXo0g94XtOC7+j7bf99eKlO+Gv/fr3lPQeL/v063abljGv4njbo0NJ8o1htNRr1wPf3bqhofeXmVSIiEa3nENkXRNu9YekLDk9Y63/vvr0zF1VX/q2xqFpPIbofBjjHDC1feNJ/jdY5dD6u8UGX47/XcVrRryTc3uD0hbUH9uzbm7SoynVPb2WO3gIexowU/bsO1LMYwnQOK4WTncGgHEhOuDww+vlqRL9y82pxqF5Zu5YVIK6sXU8K1Zb8a+1GVpi21nrrOs9l/Pso9cbw+8n1RoueGIDWY8MxZmj5IiIcOofGbRi+d/gijVqtQ+cx4BozSjPGNEIG6mhhuleTWg0GRG0HiHmUaB3hQhcOb2iE6nvJdxMYK61D5zJYjBmRwkOu3mu0Do37oTZAtO4LonKtQ+exqRkzajLGJEIG6hysgjRMepcoq6zRQzW0Hg+OwYAo3Ru5nig5s6+FZpiGxnXRXnCKEB5y9I4g3S6X166p+mKR7il6Ly1wTwdEur6YRrhAnVOd1g4YmgYt/WzjaE4iIlQfoobqlrXOgfcJc81gQJQ3IHj/LlLQqtRF03lraFYfPPviyvr15DPT0Hr71PoiZw5V2uhRgxKtQ+ftoumLSYQK1NJh2uuqLld4Ln1t7kmGdrBuPVT3WqnLDlXM1+7RFy2Eh3kgTE9n+G7Gf7fetT8PrepDZF8QIWD0RumYIXF+VBtoHUzDyhdhArXXMC1hUMkAXcLo9XBONjxX5aKEai2texiIPPuCiM8bWqus08KXZzS2vXrQegqzvgtpr+S8fkRfRPLEQNT7OhfexocUOL3RY6hOJWrBKxfp+xbnZ9W4x2r7IkSgzulwHLF64cmQ8+AOEdpVOaL0a76ydp1W11aLrkuDiFrPIZIviPgXnrRWWaMEiN7DdDQ/DHgZM1oO1bl659J5VE16gdMbJb6IGqpz9M6h9Sg6j3KdRHqLspq+CBGoU4kWMCKJfxpcIULz7EO0yRIH1tWLaVqX3ppqRbSJUkuesNR6K/qVxHLMyA3V3hsyEemHaWhcDg5v5FblooXqVL1D5+3A5Qui9PGixBfNBOoo1YuWTWoh+q337ixApOrIu9Zb9sMoHNurpSdKnj2R2pTJIkz3omEJECDq0KrUQeP61IwZGuHBAq7He059fejcPbVzqdqjprPYJfKqyngP0ytr17Z+eqH2815eu5b9nef+bqP+PiTDdMn3vu09O9R6Dtq+6MUTRGWVuhKtj2o88vfljVpfZL1XolZa6XBcek+Hxu2p+R1IjhXaXLmZ/lmy7wfQeTg0fJHrifCBWjpM1wQMK5NeWbue1cRNEgQIXqTDdAkIF/lw+CL5vRr3BJHetteI300kaidJLQWIWUiHadzP/YFQnUZJmAZxKb1XSfRLCb3lWyNMlyBt0NSwXBKqpTpb124nzdmm0dJW11EkdVU66fJKrvatOrrXbutrbUufNF7v6WA78AUPrd3Xe6fUF714ImvxADpvipJ5fIovcnZGhA3UkmHa26RLs9o8/l6cQUPz7ENroTr1DCmR3lZAS7g9Yb34pDVRIkp7frt3P4wi3aTGWuspeNmRRBTPF9GQ0nsEnWvieVG2xBcte4IIYRrw9KqpIWygTiVimPY0OZII2JrVB6K0ADFcV5QQMQ2NrYAWePLEwOg1cU2mNCZKqYtNEbocS4Zpz5Muj34Y8DJmpPoiUkUOYXoyHvxgsSib64sWPUGkG6Y9aK11OHzB7YkUQgZqiXOklkE6kkE5Q4RW9aHl54+O0lqYjuoLIr8Tpa3XDzZhmkRPYTqSF8bhHjN6DdUSeke4sIXLG1YBwgMaeofOdeHwhYUnwgXqlsJ0dJNyDgZEPqpyUZHUu+Si0bhuontioJWJktcux1LNc3q/p0ujPVEiaiNAXLl5jfbs2zP37yFcxGX4Xr0EiAhzJkm9Q+c+qPGF9hbwUF2+vYTpmg6YQwfu1szK8Zlyv1OpR6V4q07Nw2uYTtH66N9pzRMDtZ8t53fQQ0dXKb3jnq5LzXcmMVZE9UMJJVqHxnXQ9EUvIEzHR/r+w9H1O0yglrhRaG4F7GUw4ggPUgGCqN1QnYJWmO5F67loTZR6CNUpJD9rsnCBFDrnofR7lLhHR/ZDjt5zgc71kfZF9EUmCb3jnu6fkt+R1nw+RKDO2XYo2bTD+6RrZe3qzB9NvFbliHwPErlInavzrvXIlFY0Ear59Y5tr37w5IloSOkd93R7JH2RopucxwZ5IzdMgzjk+iJFC7VjhGig/uijj+i5556jY8eO0cLCAn3wwQeSb+euA6aUQUsD87zALRG6PVbliNK0wrGqJekBL01qvEy6UvRd8yNB6wGCU/8ewrQXrUthtQA7isREaUC7KqcxB5IM08APkr6QRMIDST5GmO4C7t9dzbxJtCnZ6uoqnThxgn71q1/RL37xC8m3chMuiPh/wZqTm9H3Wl7ia0hR2lggt9EGEbE2oKltyiTlAS96txiIrCb7Xrwh0ahMqgENl/4lmjJlX4PTSZeUH0pfl8sbV9aui3gi6fWY/CA9B5LQu1edp2K5GDQLr76QbtqnmQNKiK53kO4J6af4iAbqZ599lp599lnJtyAiP+GCiMecXgaE8evgGBByBoO71xH3USkSHvCgd+1ByIsnBiZdT60/pAKEpR+0xgAiOb17nHB588MonOOGhCc0u35r6n8WqXr3qPV5ePbCKFa+sIbbA5zV6bIz6jH0FpkSb3CG6tIxwtVjs9bX12l9fX3rv69ds2maYFGpi2BSrgpdSbU6cqjOYZ4HPOhdsydAJDj8YR2qrSkZA3KJFqaj+WCcWl9YheqVm1dpie5Nel8ucvTPvdUb4UIXLV94qFLnoDEGEOXpHTrXZfi+c31hvdDkKlCfPXuW3nrrreS/L/H4FM0wHdmkXOGBSGarK5GvQSKVWR6w1ntdk7nJ1z5oJ7IXJlHjD8tQbb3AlDsGDHgIF5uv35aOuSn1hdX2b+2GTKX6nwbCdAw0fBGFWg+kaB5hOgYlwTrFE1KLTK66fL/++ut09erVrZ+LFy+yvK7HDpgtmbS2iY11ow1PXY45POApTM/ThnUDJA1KPqOlJyz9UKJ/6Y7eqbSuY26sPeGhad84qfq33Pbawz3bEonvNpIfZnlA+xqhcx9Euee4qlAvLi7S4uJi0t+17viKIL2T0m0aRPZbXa0rcwPTPMDdlEk6TLes81JW1q6aV+W879rIGQOIfOgdWi8nd8zgrsh580Ou/rWB1nXIGSs4PeHBD9IeSL2/Q+v+SPUFZ5V6b8axH1cV6lSkHo+VQmlVWmOF5fLNa1k/UpR+TstHpbSAl46vGIimY12VI9J/dFAkEKZtyPke0yfEfdz3J8FdnY5SIWqJnO885ffYgx+4PiO07hfPvxvRCvWNGzfoiy++2PrvL7/8ks6fP0/Ly8v08MMPF72mZYdjL1VprjA8/jqH9zA+dkShqcDwe+NsQsNdpZbwwCQ86N3qRie5ODQOh0ckq3Kc50c5mjJJ6t/y3LTnQZ1I1xNEfL5orSonoX+uhVNU6trC8uzoLLg8sLJ+jZZ+MH+X3izSFh6gd++kjBVcfshBNFD/7W9/o5/97Gdb/33mzBkiIjp9+jS999572a9n2eHYslKnNTmSCNhSTQW2vwdviOAM1dweqKWFMK0dFlLeu8QrUgHCU1dXa/33EKYt/TDvGnJ9we0J66MQFvrnbMrkTevz8OCFeUh6wiNaHuihAj+Ohd5n6bfmerz6YmU9/TOJBuqnn36aNjY2WF7LssOxRZj2MDBwBmzJ86OpWJwP4vTANHqo1HnwwyyG67MOEDmk+KG2y7GU/q2aMnkIGN69MEqJL7gnStxViBy49d/L8aUUIvlglNHrTvWFxdlRrrmSxhyIi9T7e1TtcSD12Ut8MQ/tKrWrpmQcWHd8rZlweTdpreA9bHWN8OigHCz1rtETIBrSAYLz2aPAR5iOqPNccn3BGSBS8dCQSQOJ6nQPGpbg8s1r7J4Ak6l57Oco0Lo8Ob7wRIimZKlVEuuOr6UTLukmYRLUXK9EA5rN1+X7DltqyiShd45wYdU0T4Pc65fyxDxarXixP0qsQO/WzSE9kvN50ZApH+2mTD1qmBtuT3D5odWxoQZo3RcedoyNEiJQp2Dd4bhmwhWVmuu3DNWtDBTcn0MyTPcYJKxDNWfXb094b8rUi75LkQjVaa8Ve2zguDbOpkzQOB/4Lu2Zp3v8jnTh+r45CxDzaCJQW3Y4Ln2cREvmLJ1AWlXliPp5dJCE3nPoPVxIhuq01+vvu7dqytS71nPg/p6wa0PX69A5P6nfKarUAPikuTPUs7AOF0RyA9HC318q+ncbP/w92zW0eH60timTFBZNmUrCtAWlXphHqVdyzwPh/Oh0NCd4OEO6yTw/cY4hk9BuyOQRjkcGJb2Psy2UvcF5dlSisSsAmkQ7Sx0+UHvo6J0Kx6SLOyyMvh7XxEgqQBD1GSIkkdC7ZriQCs8p75XjF8umTFFDhBTsu10chWlNP0x7z1RfWDVk8vRYOU16a8pk4YVZcPqCyw+tjA097sQCm3hq1hc+UKdg/fgUj0E65T1qArZUgCCK8fxRa6yaMmlMtrxMlIbryA3WCBFyWDRlssSLF0ZZ+PtLZqG616qcVqCw1vssPHphFG5feHwOb6uU6t67Ji2R3tnExfJi+pwodKDm3Paag1aYtjYjR/Xa8rEQray+juO1KZPkZMvaC7PImSgR+Q4RnkO11nZvD3qfhWcvDEiF6hSwa6MM6e3eEXQrTe5YUUuvC0xWQOPppHoh0rbv0IGaE0/hwqMpS6pxAxKhupcQUYJFUyaJcOHRB9OQDNUpIETw6n4eUXYdWSIRqjW3911eu0Z76V6V96pBS/c5mm9d2zVwBglP2117B5rPR3uBSZqwgTpCU6ZcIhiyNFhbherWQoTXpkwcRND/LKRCtfbWb49Eb8oUXdulWIXqHseGGrh036vOc2ktSAAAAgdqLqQen5JDxEEI50fjwvksUqKyal1EzadgGaq5dm206gXt6nSrGs/Fcvs30AN65wd+4EHzWcSgX5oN1Jrb/0bxEqYP37e4488ur66zv09L50dbQLvbpcdtgJO0X0KpXyy3f/damfPWlMlLuODywiRy/MFdkdMaG9CQaRPPzciigip1O3i530ekJR+EDNTaD5uXOEfKZcCcCZNUyG7l/Kj3ylzUpkzSg41UaBh/XcsAQYTzctK0sO1VMkBPei8JT2hW5VpcXBpHozrnMVBoemEU63Eilx48AIAGu6wvQALvTZlqB5/D9y1u/dQy+lo1r7fw95eyPlfq98V5phHPKvTVlKkGTg/kvmcqVn5gaUDUmFda3vJn4YXx904l1RMpftDyAogB11yG4zoAAP0RrkLtsSmTVpjWuFGPvkdJ9dpzE5rIpDRl4lgwSNG81TZvLxOVnMqc1/OjLVUlPOk+2rEGLqQ8AfzjfU5jQe7uDUlanxtFolW9T8KL/jVpskI9D86mTBrhIkr1YUCiMpcCKnOz0a7WcIQLDxWHSUhVqlNAZS4Pre+CW++zfjzC7QmuKvX812j3nu+JKDrmovXPB/LoTQ+teDynj0Zzgdrr4Fgy2fIiSA+hmmvrt1d91NJaUyYv2p+F1VZXLVpeXMpF4vfSYsDg/gye/ADKaUHbJWh8bu3HWwIAJhMqUPfSlMnj5KrkmqJW5noNEtZNmSIGC8/nR+e/Rnyda233nkfq7zaixnNJ/Wxc48O83x92a8xGOpC1rHUOPDZ0A3ngCMt0evJ/uDPUtXh+FmkE4bXQ2bVHvG575db88n27i//tyuqton/n9fwoHhvkK0xp3t9rfDBOiS9SPYHz1ACA6GBRBBAFCtQpVUNPzWmI9MN06iSqNDgMSIXqFDgeHdRSQyYiP7q3WDziDA6jr5XrEe5QnbLAhMdo6cChe40wzemFSa8r6YlZYLEVlMDth9p5UynQPwAxCBOoOdCsVmiFi5JBoyY4DEiEaq6Bg6My5/2Z1Dm0VqWTCg6T3iPHH546u6bS2uKSRyTDtIYXxt/LKliAeGjvupP0w/hrp/og4rgAAMinmUDtqSmTRpjmGjhKBwmiu9fOOVigMpeHF91rVOk0w8P4e3JPnrQWmPDIlNlEOz9q4YFJ18DpB2z7BgMe9J1Kjg8AkIajUAbqCBGoU57By/I+is1piMomW9IDTskgEfG8HCpzd9HoEqq9C4Mb7hDBBRaXbJE4O+dB7/NAmOgH6U7rEfQOgBYcftDwFO7/OwnV5bsGlu7PjANLbsBYvm+32sBT8l6cnV05vmd0+95EQ/fzfqc1uzA8TbZyriXlM2t5YR4tdPuWoub7z9H9oHVPep9H6rVGaLYJQAmR/Ar8E0lPka5ViyYCtZcJYc6jU1KxnGRJhWoO8OxFP7rnxnOwsAjVtXg6Qw924lXrKUS+dmBPC/pp4TOA2Wg0hYuoo4jXLEmILd8azAtoXJWi3DBtjcTWPs0GZbNI2fYd/bFB86jVPXd1mkPzqe9Zui3b23ZXbPuOi8Q9vmZhE82TAAAAgHy6CNQaFRruShPnRKu2eZjX86Pz6L0hU6TKZI3eSwPE+L/L0W2qJzj8gMemtInEPZ7rdSS8AAAAPYJjL30QPlBrPINXuzotFS5G/1/uJN9jZ1dU5urwUJ22CNLzXi/VG1xBwlOzPqCD5k6M0tf2sjAK/KJxZKWEWm9A+wCkgQXVu4QP1PPwUqWTDNMlg0eESoSXbd/AF9KrvTlhAoNJv8wKE1Ia1ax0IFSDSHB6Q+KRoACAtmk+UGvAtUpr0QRMqirn5fmjvW/79oznpnecYQLBBNRitWUQ2gVesPAA9A88IukF6L2c0F2+I233nkdu92Cp7a4peHpcCrp921C73dtzmM59Tw/NA0GbSNzrS64BAEugQdA7w1igsUPPw7gTkdCBeh7Rtntrv1bNa2uFCDyH1wathaQULG/sGFT80rpvoT0A4AMArID38mg6UM+Do7qp2ZRDQ9zaoRrP4e0P7mc5T+KBfYs7fkrBoAIiwqH9AXgA9Aq0DwBIIewZao3qhKft3jg/Oh10+/YF9yN8UpkXHEb//7c3cE4IzMZyl0bNQlLKn0P/AADgg3kZAIs6Mei6Qq0BZ+OwUkqqFJ4M7Gn7MdCBO0xP+vs5/8aTHwAYJ1fPHFVrAKThuu9y7dQAoDcw90knbIV6HvO2+XrZ7i1xFnlelSK1OpFSXeZ4bBCewwtKqZ0kPbBvEdU6EJpSD+SOBwBEIWWnBnQPAOAEFeopeKmKpq4O5ZyXQ2UOeCZH8xygcgGiwqFd6B+0Qk4lGlVrAAAnzVaoPcD96KBplAwKmpU5PMsRcIOJEOgdeACATeAFADZJ9QJ2aPCDCrVjUip1NQMJ1yCE5/DGo+bIg2Zney0wIYvH8tIB60sAAAQH937QCh77aPRUTEOgLsRDqNDa7odt30CTnm7AAHgAoQJEBdoFoHynKuADgdopmiEWpgKcIBADAAAAwAOHlvZbX4IoHnaqAqVA/e6779IjjzxCS0tL9OSTT9Inn3yi8bai1Halrt0mDRPEoUX9A5AK9A96Bx6QAfOgGETXv5cmxcA34oH6/fffpzNnztCbb75Jn332GZ04cYKeeeYZ+uabb6TfGmSAgUmGFvWPR5yBVFrUPwA5wAOgZ6B/0Avigfo3v/kNvfTSS/Tiiy/Sj370I/rd735He/fupT/84Q87/u76+jpdu3Zt248Vh/eg4c0oOEddRo7+iXx5QIra55aDOED/oHeizoEA4ABjAOgF0UB969Yt+vTTT+nUqVN333DXLjp16hR9/PHHO/7+2bNn6eDBg1s/x48fl7w8AETJ1T8RPADaAfovB30I2gBzINAzGANAT4gG6m+//ZZu375NR48e3fbnR48epa+//nrH33/99dfp6tWrWz8XL16UvDwARMnVPxE8MIBAER/oH/QO5kCgZzAGgJ74gfUFjLK4uEiLizpbi5eXDlY9i9eab2+ss557nveQdwQcHTQ9EBlu/QMfaOo/8v0ftAnu/z45fN8i5kBKwAO6zJv7g3REK9QPPPAA3XPPPXTp0qVtf37p0iV68MEHJd/aPThH2j496x+TD9Cz/gEgggdA30D/OiAU+0A0UO/evZsef/xxOnfu3Naf3blzh86dO0c//elPJd+6+efOEfGZCGaUwVL/AFgD/U8HC6p9AA/0Qe1jUFsF+gc9NTQW3/J95swZOn36ND3xxBN08uRJeuedd2h1dZVefPFF6bcOzeXV9SQh1m59RZiWBfqfzMrqrepJCOe2b/hABuhfDug/BvCAHDj64x/oX4cSL+C+z4t4oP7lL39J//znP+mNN96gr7/+mn784x/TX/7ylx1NCnJZXjpAK2ttt9OXDtWpZsL23XKk9G/Nxg9/Twt/f8n6MlgmVBhU5GhV/xqk3v+BbyJ74PLNtudYQJ7I+o9GznwI8x5+VJqSvfLKK/TKK69ovJUrNCdEucGC00zYvjibXvVfi5cFJVAH9C8HdijFAB7wB7Svh7T+eyiwpTJvTIDu5XDV5RvsJCeUp0yucs2E6nSfHN5zIFR1IjVYYDABGmgvphIR9A+6BJoGtbT2xAd4wgYE6gpqt72mniPNDdVEdydX0sZKqU4jlINSSrQ/8MC+RQwsoBugdQBkwBwG9Aq0n45ol+/oHN5zwPoSivn2xjomWGAqy0sHrS8hmdIbOvQPgA7ocgwAAKBnEKiNST1/bLFKNO89uarTGz/8ffI1gThw6McLWKUF3GB3DwCzgf4BAFHoOlBrVOlSBgSPodrTQBZ5pwDgwUqPl1fXXXkB9Af0BwAA/YIxIAZdB+qISBuLM0CgOt022r877QUlDGLAC5ZahBcAAKA/cN/Po+lAfWhpv/h7pIQKzir18HrcQs99TU/bdSOdBwbbydWRxwUlT14A7aIVbIf3QZAGHrDWoPX7A0Ckr0PoPh90+XZEatfvAY5Hs5SYRvPsNLZ726H16KwS3Q9wPJpII6QDwMWgJ67HckGfwAqJJ52kwK15LKoCDWp1m+IhjAflhA7UGg9zTwkVKY/PSh0QSsNFzmDTkmFSqtMaOxVAHbm6H7DWPyZSYBrSz6KepONZ79fSfR/0B/QLQB3wkCyhA3U0pEL18NqjjL6PdoBAdRqUUBqqiWIPFOgj0C81mp9EZB8AAACIBYoKd2n6DHUKKRXOlGDHPSmuFanEGThvxuGqTi8v9RncvXS5H8Wbxmah9dgjLCz5hOueH0nz02jhMwAAgAW4f7ZB94GaE64GZQOeTMb5aC9Up3WIutV9ZfWWK+2Pw3l9qE4DIl/3egC4wI4JAEAvIFATX5U6lUihOic8aA6eqE77gHsRaRRr7Y8y+CC3Gz+Ii/ainie95xD1ugEAfXBl7br1JYAOaD5Qa1fpJCpOFhMWqfCA6jQfGosBXL+LmlBtNWEvCdE5cHkBj41rhyi7M6S9AfohuoaiXz/wQUQdRbxmScIH6pRQkVap9FulJpKf3Ne8h3YlTrM6vbyIcD+P1EWkGp1oTt453stTdTrq1n9pPPYQGLAOrJOCc+m1ePIC8Em0xRlrf4I2aVFPPd3/0eU7E67HaBGVP1ZlMB1Xd9gaE+eYJVp1+vDSAbp546b1ZYARRrXK2R2ZcyDjGkBQnQZE07XJof8WJ3AgLlL390mvD4BHPGh0+b7dLq4jGt0E6kNL++eeo1heOkgra1dZ3k86VBPVDT4cZuEO0yng7DQvKZrnXkQiyntu9DRK9S85UHAefeAAXrBH6nnUrUx40JgPTKIVfQMgNQZIAe+VEX7LNxHvhJBz67fGVtiBaVv0BmNwn3uTCNPeqtMgj5yJMfc2oFn61zrzyfmZUJ2OgeY9PiJ4bBwAAIAeaCJQE/GdpU7FY6ieBneIsKhME6E6LYV2/4CBlkKGlSdmAS/4oiW9c4HqdPtA9wCAqOT0UQoRqDkbQ3E1KJPg8uq6+8FHKjh4qkK0VJ3WXkTKnSBH0PwkhuvOvX509o4Ft+aj6j0Xzc85zwtoygcs6cHvAIAggZooLeRoV1u4q9QD3iZdUsFhgCtA9FiR0+xyn0pJ1cmb5idR4oNRNKtx6HLvG+9az6V0gWkenhZaQTmt6R2AXOCB9gkTqFPRDhhSoZrIPmSUvn/kbXwtVadzsegfMI7UxLwGzWtBdTomEe/vpYx71HKBCV6IQ1S95+JxDAMAyBOqy/fhpQN0eW12t2FOUrt+p3RBJkrvhDzO6E1Zo1NgzSCQO0lCdbqe5aUDtDLHFyld7lOR1vso2tqf9L61aC8wcXmhh8fGcXW5J+K5v2+9p3FHWOkg4OkRiq2OCxqUaD5ax+NptBKWoX89xjXTgg8m0Yo3cgkVqInSQrV2wMihNmRIBQwOA0iEaU16rk4PcD46jognVA9Ih2uJQcDi6AO4C9d9XnMRiWi+Fjn038OkB+en60jVfS49aC+VyDv6QB3wQVuEC9SccD6bOmfgkZh0lUywrKpwOUEa1ek0vFapiXhD9cAs7c7yguYAZjFR4qxO94LnRaRpRJ6IeWrM1/q4oIGG3gEAwDshz1BrNyjjPk9NxD/ZnnSubd4PF1G7eY/SS4Cw6B9ApBsuNTQ/D6ujD6AM7kfHoeo0GW+N+QCwhGNxCeOCPbjfl9PSdxcyUKfC+WxqqZARWUy5158bplGdvktKt+XeFpE8UuJprkWmHqvTnPf4FLwuCHonxxeeFpfQ5T6N6HOZlsHCEgA6hN3yzdmgjPs8de65o2EgirJtqmTglAjTXEQKEPOw6B9gvf3bCo4JZKovUIWQR6IJJVGc+7oEViGrl4VWDXq9v0vjqTEfAL3COQ6EDdREfA3KUsk5a1fSzGP0ButxUCqdHEmF6d4mTdqLSFJ6n6Qjj3qfBFdAsJgotVadHsAikg+0Fpi0Fpd66HIvQS96LwFV/HaB7kHoQJ0K54RLOlQPeKlu1A4AnivTRPECRGuLSAPTdGat/wHOiZDV0Yfe4V5EyiHyItI4UqHA29GHXuB8dNyAl/mLFS0tLuHYQzq96z6HFheXwgdqi63fWiGDyK5q7T1IY9I0m4iLSJOw3LUhccO3WmBqtTo9YLGIxHlvH/AwEbOY6Hg7+hDZC1LU7roj8qHvcVqc2A9godWG6Jri8Gn076CE8IE6Fc4J1+br6YcM6XBhtZ1VIkynEHXS1Poi0jQk9a9x87c8+tADFotIkgtI02htssN5/AELrTuxejzoJDzpzjNeqtOgT+DTMpoI1FYNynJDBhGxTb44Vn4jVuDSu7IzbR8M3BSkhUWkaUS74VsefWihOr28eIC+o+9ZXst7qJ5HNO1Pw+txIO9eGIfrPu9V772Bow/+gObtiPTYuCYCNRHv2VKpUE2kU72zwkuYTiHpWeZ7DtJ3N75je09Ooiwi9T4IlUyOcnyB6vR2uBeRUoHW8/B89KFFrJ9kAtLwePShh8Z8En0EQH+EeA41Z5UwdUDNmajm3twO7znQ1OMQSj6PZJjuZdKUtChgrPfWtJ7C8JlLPMEdpluoTg9wXmf6Tpc8rYPZSI4VHItLUbwgBfRuB44+ALAdDk9oFh1CBGqizWrhPFIHQ+uQMVA68fZAzbVbh+nU6nQreNB7VJ3PY9QHNZ/RcrdGJCwWkbCAVIfmWDH7tdr9vaR8Niwi+STXGzj6kA9b3x3oXY2I33UzW74HOLfCEslu/x5lVDyet5XUiLxkIEBlejbR9B5F57PgvtFb9hFoadI0CvfxnpKjPURxNV6CpS9aX2Di6iEg1YSSqC+t1yA9h0J1ugz0EPCDt6MPqYQK1Mt7DtLKTZ5nhOactdMK1QPeQgfHREm6Apc6QLRYneZ+NjX3ebtpzNKVB92PI7Fiisp0PtyLSKnULiAR+dR1CtrVAu6JUg+LS5ZNKIkQrMexXnitIboXSskJ1eNA9/lIjyva86VQgZooLVSnTrgkQzURVQdrIttwzSV2L2G6dyT0zqn1UTwEEembfYSjD1673EdpQjnONE15mIx52GKHBabpcC0kae5CGsWDxkfxoPdUcPRhPvPu99KFgkh6agFv1WmigIE6FetQvfna9dXqUaTDdcQKXM7g0GJ1esBa79xaH0dK+1aDoHWY7gWPoXoSmIzh6AMHnvUOjZehffTBqxc4jj1wPpMd2OH16INYU7K3336bnnrqKdq7dy/df//9rK/NHXpyvtT8wJfXuTeVSc2QZv2k/FtOSj53a5VpSQ/UIKV3Ka2Pk6v9VF9ooOGLFDQWl6T1H60JJZiOB09IYDEGQO/tYHH0gROvc6B5QO+AKH9xSSxQ37p1i55//nl6+eWXpd5iLjlfhmSo3nx9nbAxDa0QUfo5pcO0RXWa0wMpW2+l9J6Ltda9UhIacivTnhaZNMYA7mqKxwWklpFeYLKuTnN7wFrvQI8WFpm0cwBnt3vgj9Txwqoxn9iW77feeouIiN577z2R109tUJZz7kijcdOoGFraVlI62JYtTvCHaQmkPTAJCb3Xar0lnafAMfFs4eiDhf6nIX20h6g/ndeisfBqjYQHLJtQYjusDhJh2mJxiVv/mg0poXVfaC/olXjB1Rnq9fV1Wl9f3/rva9fmDBpBQ/Xd94o9EasVuIeq9NZrOzk7PcsDlnqv0Xp0nc+D+0bf2tGHHHLHACL7/gF3X79tnZfC5Q8JX3g7L1qi/2lEaLoKNtEsSHin1gMpurduugry4O4jIDVnEtvyXcLZs2fp4MGDWz/Hjx+f+29Sg5Dk9u/am9qwjSHKFkKO6/QUpj0xzwMSek+FS+ctIOVXD76wXFwqGQOI+M9TE5XrvSWd5zA+jnF+D70sMqXq34Pee9V5LVweiXT0IYfSMSAXHO/xi3UmKvVCVqB+7bXXaGFhYebP559/XnQhRESvv/46Xb16devn4sWLxa81CckzphzB+u57+zQv13V5CA3bXj8jQETygNSki3sBKcpikvR1evPFJCLpfxoaoXrzfWLoeh6z/KrhCak+AqWPjZP0QI7+PYTqzddvQ+cDqXov/eHAsjJtPQYkLQoLLQ5EnbvMwvLzcL+3ZXWaKHPL96uvvkovvPDCzL/z6KOPFl/M4uIiLS4uZv+71K2wRHLbvweGXyjH8+6sz1tLmMpbaMitxnnwgITec7XOqfPt1zH596Gpf+3B0VMfgXl+8KD/aXg92rP5fva6noXHCaHXqrSkB2r0PwstvXvUUWtYH33wPAbkwvls6ta0H+3zeDj+kBWojxw5QkeOHJG6lio8hWoi/sAhHa6lzeMpNGy9fsHWVi8e8BCqieSC9TgSgcTDgOFtgWkeVvo/tOcArSU8g1QyVBPpLSD1jgdfLO85SN/d+G7Hn3sZA4h8LyIBfjwsMnnQP2djPmg9Np6OPog1Jbtw4QKtrKzQhQsX6Pbt23T+/HkiInrsscdo3759Wa91aHE/rdPtuX/PW6gmkjFrpEmYRpAm0gnTuXB6YBI5ek9+TScLSKlE8sI4HkLDttdn9gS3/q2bUBLZ6bwnvPmiBukxgAihuhekfCHpBw39zyInVBPhvh4ND1XpUcQC9RtvvEF/+tOftv77Jz/5CRERffjhh/T0009Lva3bUD3Qg2Hrzh3GCg2z0PCAh5AxCgam6fTmCwn9e9E7dM6Pp11MXH7QmgdF25kB0vFQlS5FUv8Sj9DCIlIcrI8+TEKsy/d7771HGxsbO36KJ1JCj0DKbVRWe7PibF7mjdrP5i00LC8doEOL5Z+H2wPTkOp0X6P1lnWewvD5R39K8eaLVLT0Pw3JJpQDveu8hlp/eK5MD2h6IErTVZBGyXcu4YlJjflSsR4DiKD1FvG6yOTqOdTzyFlZlapUD9dBRMVVPKK2Vn45bj7eQoOnVd4UJCp3RHXVaqK2dD4LqQHYmy884HkXUus6L4XTH/DEdCSqdqNA53LUPz3D/wITNy30hwHpSC68cvghVKAmkgvVpddCxBOsB6KYt+UJUrQwnQsWkOqRXsFupY+AFJKhmqhc663pfBKW1RtvY4UWqU35iGRDxtb1dKBzKST8I3n0YVJjPk9I6x1at8GiUFdLuEBNJBOqhxtMyeouR+AY8Hzemnsg8BgaIodpyV0ZRDILSAPetD6KdoDoNTTkIr0LCQtIvpq+9O4LqSc7ENUvIBHF1zqRL72n0mNluhSuXkjTmOeBiPqKiJUnQgZqIj/bv8eviYgnWBPZDlbeKnAlgm8pTFt3ut/2Hsw6J5qtN03tWw943kJDTQ8BDaIc7ZmFdRCx1nwK3nxhhdedGUQxdNQakr6I4gkivaM984AH7LFcYAobqIl8hurhuojkAgf3BEzzJuCxKk3kO0wPpOo96gLSNHoZpLyFhuWlA7T6/WrWv7Egws6MWfSi71K8+cIayaNsWvd0UAc8sRPtBSTgD+vdGqEDNZHcalPNFvABKdNGm4DVhFVs8S4jN2QQlWsdg1MdHheZovki6s4MMB2PvvCCVBPKrdeH1t2CMD0di11IwAfWYZpI8LFZmqR+kSU3isNLB6q/eI7HbUWk9nMjNOxE6vFxRPU3mF51nsPwHY3+5AJfTEbqcYk73gc6F6Xk+y0ZpyMHB6L066/VOvADwvR8io4H4p4eGklf5Dw2LnyFekBiO+wonivWnuC6KSE0TEey0z10zge3xnrvI5ACdmbEgkNvPYaGgWhNV0E+pR5pzRcSne7HgdZjIV2QyO1y30ygzqHmDBJn4CBqx7icE3GE6flIPz4OwToPaU313kcgtSkfkf4iUk86L0FSV7035cslQs+MnolSkLCitf4wIB+tBaYSmgrUuSGDiEyDNdFOcUQysHUFTiM03L+0L/s9tNB4JjsWkHaiHTyxwLSJ90WkHiZhnrSCpnybYAFJnlm6H74HL95oNUwPWOxCIupL716ItsAUIlDfv7SPvqeNpL+b26TMS7Deuh6ng1X0ClzJ9R9a2k83vr+R/e800QjVRP0uIFlPkjz6whKtRaTed2Z41wV8sR3LBSSi2Fonqvt9e9GKxpEgL5QsInHPXUAMNBeYQgRqos1wk/q4qJLO37WPopAK1kT6g1XvFbiIXdSj7czYup45vxtN7XsbML35wgsRd2YAHtBHYDrQer+0XpWehEV/GBALbV+ECdREOqGaqDxsEMmYlmOwGv8urAfA0vMMCNOTib4zYxrWOrUAoWE+0XZmgHo8HgnyBrTeHz33EbDqDwP8Y7HIFCpQE8mHaiK/wboG64kCR0MAhOnZWCwiedN5VLQWmIjs7wVcRN6ZAdLBAlN+Uz4iaL0H0EfAdmcG8InVjo1wgZpIJ1QT8QZroj6Ny9VZD2E6DatFJAxO6UTxBJHvpnxE7e7M6J2qZyc3FqYHSrTeUlEA3AWLTNvBzgxAZN9HIGSgJsoP1UTl5zE5gjVRP8blbE+v1XzMO5KN+bb9W0zC2JB8TIPWApP3pnylIFj7gNsjLYcGIv0FJCKehk6gjlqftO4LIsxdesY6SA+EDdREeaGaCMFaEonwgKr0drAzwycazzccBb7YjqXWW7yX56Ct/Vn0EBqIcLSnZawXmIji+oKozeOaYCfaC0ypuA7UGxubFbnV69PPcNxLC/SvtbwqyiLdQ0REV9bTw/goS3Tv5r+/WWe4vf9+nYGV9TgGXl7cLuibN26yvv6hPQfouxvfpf/9xf1ZZ33uX9qXVH0btDdoUZtxD6yupX9GbzqPpO9pjOueiF/7s9D2hRf9z/vMi3RPsc6J6rU+ei9vQeeTsNb+NA7t2bwuCV8Mr+lN/6V6h87zmKR5STj9VDJWENEOX3jxwM2Mz8Ixd4k8Py+hVOul30uNt2p8kuuLxe8359Ep+l/YsHJJAv/4xz/o+PHj1pcBAF28eJEeeugh9feFB4AHoH/QM9A/6B14APRMiv5dB+o7d+7QV199Rfv376eFhQXR97p27RodP36cLl68SAcOxN3yMkqLn4lI93NtbGzQ9evX6dixY7Rr1y7R95qElgeglThA/zJAK3HQ+lzQf3xa/FwYA2SAVmLgVf+ut3zv2rVLfUXswIEDzYhuoMXPRKT3uQ4elDlvkYK2B6CVOED/MkArcdD4XNB/G7T4uTAGyACtxMCb/vWXmwAAAAAAAAAAgAZAoAYAAAAAAAAAAApAoP43i4uL9Oabb9Li4qL1pbDR4mciavdzWdLqd9ri52rxM3mgxe+1xc9E1O7nsqTV77TFz9XiZ/JAi98rPpMerpuSAQAAAAAAAAAAXkGFGgAAAAAAAAAAKACBGgAAAAAAAAAAKACBGgAAAAAAAAAAKACBGgAAAAAAAAAAKACBGgAAAAAAAAAAKACBegJvv/02PfXUU7R37166//77rS+nmHfffZceeeQRWlpaoieffJI++eQT60uq4qOPPqLnnnuOjh07RgsLC/TBBx9YX1KztOAB6B+U0oL+ieABUAb07xPoXw94wCeePYBAPYFbt27R888/Ty+//LL1pRTz/vvv05kzZ+jNN9+kzz77jE6cOEHPPPMMffPNN9aXVszq6iqdOHGC3n33XetLaZ7oHoD+QQ3R9U8ED4ByoH+fQP96wAM+ce2BDTCVP/7xjxsHDx60vowiTp48ufHrX/96679v3769cezYsY2zZ88aXhUfRLTx5z//2foymieqB6B/wEFU/W9swAOgHujfL9C/DvCAX7x5ABXqBrl16xZ9+umndOrUqa0/27VrF506dYo+/vhjwysDQB7oH/QOPAB6BvoHvQMP6INA3SDffvst3b59m44ePbrtz48ePUpff/210VUBoAP0D3oHHgA9A/2D3oEH9OkmUL/22mu0sLAw8+fzzz+3vkwAxIAHQM9A/6BnoH/QO/AAkOQH1hegxauvvkovvPDCzL/z6KOP6lyMMA888ADdc889dOnSpW1/funSJXrwwQeNrgpY04sHoH8wiV70TwQPgJ1A/9B/78AD8IAk3QTqI0eO0JEjR6wvQ4Xdu3fT448/TufOnaOf//znRER0584dOnfuHL3yyiu2FwfM6MUD0D+YRC/6J4IHwE6gf+i/d+ABeECSbgJ1DhcuXKCVlRW6cOEC3b59m86fP09ERI899hjt27fP9uISOXPmDJ0+fZqeeOIJOnnyJL3zzju0urpKL774ovWlFXPjxg364osvtv77yy+/pPPnz9Py8jI9/PDDhlfWHtE9AP2DGqLrnwgeAOVA/z6B/vWAB3zi2gPWbcY9cvr06Q0i2vHz4YcfWl9aFr/97W83Hn744Y3du3dvnDx5cuOvf/2r9SVV8eGHH078vZw+fdr60pqjBQ9A/6CUFvS/sQEPgDKgf59A/3rAAz7x7IGFjY2NDe6QDgAAAAAAAAAAtE43Xb4BAAAAAAAAAABOEKgBAAAAAAAAAIACEKgBAAAAAAAAAIACEKgBAAAAAAAAAIACEKgBAAAAAAAAAIACEKgBAAAAAAAAAIACEKgBAAAAAAAAAIACEKgBAAAAAAAAAIACEKgBAAAAAAAAAIACEKgBAAAAAAAAAIACEKgBAAAAAAAAAIAC/gvGtH3M/rzi8wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sdf_cm = colors.LinearSegmentedColormap.from_list('SDF', [(0,'#eff3ff'),(0.5,'#3182bd'),(0.5,'#31a354'),(1,'#e5f5e0')], N=256)\n",
    "\n",
    "# Calculate distance function and plot\n",
    "\n",
    "Z1 = model.apply(params, xy1).reshape(n, -1)\n",
    "levels = jnp.linspace(-1.5, 1.5, 21)\n",
    "fig, axes = plt.subplots(1, 5, figsize=[12, 2])\n",
    "for i, ax in enumerate(axes):\n",
    "    xy_ = jnp.hstack([xy, i/4*jnp.ones((xy.shape[0], 1))])\n",
    "    Z = model.apply(params, xy_).reshape(n, -1)\n",
    "    ax.contourf(X, Y, Z, levels=levels, cmap=sdf_cm)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x7fcd03c02e50>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mid = 1\n",
    "xy_ = jnp.hstack([xy, mid*jnp.ones((xy.shape[0], 1))])\n",
    "Z_ = model.apply(params, xy_).reshape(n, -1)\n",
    "fig, ax = plt.subplots(1, 1, figsize=[4, 3.5])\n",
    "ax.contourf(X, Y, Z_, levels=levels, cmap=sdf_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
